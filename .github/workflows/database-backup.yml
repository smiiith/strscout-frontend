name: Daily Database Backup to Supabase Storage

on:
  schedule:
    # Production backup - runs on main branch at 2 AM UTC
    - cron: '0 2 * * *'
    # Development backup - runs on development branch at 3 AM UTC  
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to backup'
        required: true
        default: 'production'
        type: choice
        options:
        - development
        - production

jobs:
  backup:
    runs-on: ubuntu-latest
    # Use environment from manual trigger, or determine based on branch
    environment: ${{ 
      github.event.inputs.environment || 
      (github.ref == 'refs/heads/development' && 'development') || 
      'production' 
    }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
        
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          
      - name: Install Supabase CLI and dependencies
        run: |
          npm install -g @supabase/supabase-js
          npm init -y
          npm install @supabase/supabase-js
          
      - name: Create database backup
        run: |
          BACKUP_FILE="backup-$(date +%Y-%m-%d-%H%M%S).sql"
          echo "Creating backup: $BACKUP_FILE"
          pg_dump "$DATABASE_URL" > "$BACKUP_FILE"
          echo "BACKUP_FILE=$BACKUP_FILE" >> $GITHUB_ENV
          
      - name: Upload backup to Supabase Storage
        run: |
          node -e "
          const { createClient } = require('@supabase/supabase-js');
          const fs = require('fs');
          
          const supabase = createClient(
            process.env.SUPABASE_URL,
            process.env.SUPABASE_SERVICE_KEY
          );
          
          async function uploadBackup() {
            try {
              const backupFile = process.env.BACKUP_FILE;
              const fileContent = fs.readFileSync(backupFile);
              const environment = process.env.ENVIRONMENT;
              
              console.log(\`Uploading \${environment} backup to Supabase Storage...\`);
              const { data, error } = await supabase.storage
                .from('database-backups')
                .upload(\`\${environment}/\${backupFile}\`, fileContent, {
                  contentType: 'application/sql',
                  upsert: false
                });
              
              if (error) {
                console.error('Upload error:', error);
                process.exit(1);
              }
              
              console.log('Backup uploaded successfully:', data.path);
            } catch (err) {
              console.error('Error:', err);
              process.exit(1);
            }
          }
          
          uploadBackup();
          "
          
      - name: Clean up old backups (7+ days)
        run: |
          node -e "
          const { createClient } = require('@supabase/supabase-js');
          
          const supabase = createClient(
            process.env.SUPABASE_URL,
            process.env.SUPABASE_SERVICE_KEY
          );
          
          async function cleanupOldBackups() {
            try {
              const environment = process.env.ENVIRONMENT;
              console.log(\`Cleaning up \${environment} backups older than 7 days...\`);
              
              // Get list of backup files for this environment
              const { data: files, error: listError } = await supabase.storage
                .from('database-backups')
                .list(environment);
              
              if (listError) {
                console.error('Error listing files:', listError);
                return;
              }
              
              const sevenDaysAgo = new Date();
              sevenDaysAgo.setDate(sevenDaysAgo.getDate() - 7);
              
              const filesToDelete = files.filter(file => {
                const fileDate = new Date(file.created_at);
                return fileDate < sevenDaysAgo;
              }).map(file => \`\${environment}/\${file.name}\`);
              
              if (filesToDelete.length > 0) {
                console.log(\`Deleting \${filesToDelete.length} old backup(s):\`, filesToDelete);
                
                const { data, error } = await supabase.storage
                  .from('database-backups')
                  .remove(filesToDelete);
                
                if (error) {
                  console.error('Error deleting files:', error);
                } else {
                  console.log('Old backups cleaned up successfully');
                }
              } else {
                console.log('No old backups to clean up');
              }
            } catch (err) {
              console.error('Cleanup error:', err);
            }
          }
          
          cleanupOldBackups();
          "
          
      - name: Clean up local backup file
        run: rm -f "$BACKUP_FILE"
        
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      ENVIRONMENT: ${{ 
        github.event.inputs.environment || 
        (github.ref == 'refs/heads/development' && 'development') || 
        'production' 
      }}