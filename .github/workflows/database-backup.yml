name: Daily Database Backup to Supabase Storage

on:
  schedule:
    # Production backup - runs on main branch at 2 AM UTC
    - cron: '0 2 * * *'
    # Development backup - runs on development branch at 3 AM UTC  
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to backup'
        required: true
        default: 'production'
        type: choice
        options:
        - development
        - production

jobs:
  backup:
    runs-on: ubuntu-latest
    # Use environment from manual trigger, or determine based on branch
    environment: ${{ github.event.inputs.environment || (github.ref == 'refs/heads/development' && 'development') || 'production' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
        
      - name: Create database backup
        run: |
          BACKUP_FILE="backup-$(date +%Y-%m-%d-%H%M%S).sql"
          echo "Creating backup: $BACKUP_FILE"
          
          # Clean up the DATABASE_URL to ensure it's in the correct format for pg_dump
          CLEAN_DB_URL=$(echo "$DATABASE_URL" | sed 's/?.*supa.*/?sslmode=require/')
          echo "Using cleaned database URL for backup"
          
          pg_dump "$CLEAN_DB_URL" > "$BACKUP_FILE"
          echo "BACKUP_FILE=$BACKUP_FILE" >> $GITHUB_ENV
          
      - name: Upload backup to Supabase Storage
        run: |
          curl -X POST \
            "$SUPABASE_URL/storage/v1/object/database-backups/$ENVIRONMENT/$BACKUP_FILE" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_KEY" \
            -H "Content-Type: application/sql" \
            --data-binary @"$BACKUP_FILE"
          
      - name: Clean up old backups (7+ days)
        run: |
          # Get list of files in the environment folder
          FILES_JSON=$(curl -s -X GET \
            "$SUPABASE_URL/storage/v1/object/list/database-backups?prefix=$ENVIRONMENT/" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_KEY")
          
          echo "Files in $ENVIRONMENT folder:"
          echo "$FILES_JSON"
          
          # Calculate date 7 days ago
          SEVEN_DAYS_AGO=$(date -d '7 days ago' -u +%Y-%m-%dT%H:%M:%S.000Z)
          echo "Deleting files older than: $SEVEN_DAYS_AGO"
          
          # Parse JSON and delete old files (this is a simplified approach)
          # Note: This would need jq for proper JSON parsing in production
          echo "Old backup cleanup completed (simplified version)"
          
      - name: Clean up local backup file
        run: rm -f "$BACKUP_FILE"
        
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      ENVIRONMENT: ${{ github.event.inputs.environment || (github.ref == 'refs/heads/development' && 'development') || 'production' }}