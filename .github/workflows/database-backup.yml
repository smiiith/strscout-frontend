name: Daily Database Backup to Supabase Storage

on:
  schedule:
    # Production backup - runs on main branch at 2 AM UTC
    - cron: '0 2 * * *'
    # Development backup - runs on development branch at 3 AM UTC  
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to backup'
        required: true
        default: 'production'
        type: choice
        options:
        - development
        - production

jobs:
  backup:
    runs-on: ubuntu-latest
    # Use environment from manual trigger, or determine based on branch
    environment: ${{ github.event.inputs.environment || (github.ref == 'refs/heads/development' && 'development') || 'production' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client
        
      - name: Create database backup
        run: |
          BACKUP_FILE="backup-$(date +%Y-%m-%d-%H%M%S).sql"
          echo "Creating backup: $BACKUP_FILE"
          
          # Clean up the DATABASE_URL to ensure it's in the correct format for pg_dump
          CLEAN_DB_URL=$(echo "$DATABASE_URL" | sed 's/?.*supa.*/?sslmode=require/')
          echo "Using cleaned database URL for backup"
          
          pg_dump "$CLEAN_DB_URL" > "$BACKUP_FILE"
          echo "BACKUP_FILE=$BACKUP_FILE" >> $GITHUB_ENV
          
      - name: Upload backup to Supabase Storage
        run: |
          curl -X POST \
            "$SUPABASE_URL/storage/v1/object/database-backups/$ENVIRONMENT/$BACKUP_FILE" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_KEY" \
            -H "Content-Type: application/sql" \
            --data-binary @"$BACKUP_FILE"
          
      - name: Clean up old backups (7+ days)
        run: |
          echo "üßπ Cleaning up old backups for environment: $ENVIRONMENT"
          
          # Install jq for JSON parsing
          sudo apt-get update && sudo apt-get install -y jq
          
          # Get list of files in the environment folder
          echo "üîç Listing files with API call: $SUPABASE_URL/storage/v1/object/list/database-backups?prefix=$ENVIRONMENT/"
          FILES_JSON=$(curl -s -X POST \
            "$SUPABASE_URL/storage/v1/object/list/database-backups" \
            -H "Authorization: Bearer $SUPABASE_SERVICE_KEY" \
            -H "Content-Type: application/json" \
            -d "{\"prefix\": \"$ENVIRONMENT/\"}")
          
          echo "üìÅ Files found in $ENVIRONMENT folder:"
          echo "$FILES_JSON" | jq '.'
          
          # Calculate date 7 days ago for production cleanup
          SEVEN_DAYS_AGO_EPOCH=$(date -d '7 days ago' +%s)
          echo "üóìÔ∏è  Cutoff date (7 days ago): $(date -d '7 days ago' -u)"
          
          # Parse JSON and find files older than 7 days
          OLD_FILES=$(echo "$FILES_JSON" | jq -r --arg cutoff "$SEVEN_DAYS_AGO_EPOCH" '
            .[] | select(.created_at != null) | 
            select(((.created_at | sub("\\.[0-9]+Z$"; "Z") | fromdateiso8601) < ($cutoff | tonumber))) |
            .name
          ')
          
          if [ -z "$OLD_FILES" ]; then
            echo "‚úÖ No old backup files to delete"
          else
            echo "üóëÔ∏è  Found old files to delete:"
            echo "$OLD_FILES"
            
            # Delete each old file
            echo "$OLD_FILES" | while read -r filename; do
              if [ -n "$filename" ]; then
                echo "üóëÔ∏è  Deleting: $ENVIRONMENT/$filename"
                
                DELETE_RESPONSE=$(curl -s -w "HTTP_STATUS:%{http_code}" -X DELETE \
                  "$SUPABASE_URL/storage/v1/object/database-backups/$ENVIRONMENT/$filename" \
                  -H "Authorization: Bearer $SUPABASE_SERVICE_KEY")
                
                HTTP_STATUS=$(echo $DELETE_RESPONSE | grep -o "HTTP_STATUS:[0-9]*" | cut -d: -f2)
                RESPONSE_BODY=$(echo $DELETE_RESPONSE | sed -E 's/HTTP_STATUS:[0-9]*$//')
                
                if [ "$HTTP_STATUS" -eq 200 ] || [ "$HTTP_STATUS" -eq 204 ]; then
                  echo "‚úÖ Successfully deleted: $filename"
                else
                  echo "‚ùå Failed to delete $filename (HTTP $HTTP_STATUS): $RESPONSE_BODY"
                fi
              fi
            done
          fi
          
          echo "üéâ Cleanup completed!"
          
      - name: Clean up local backup file
        run: rm -f "$BACKUP_FILE"
        
    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
      ENVIRONMENT: ${{ github.event.inputs.environment || (github.ref == 'refs/heads/development' && 'development') || 'production' }}
